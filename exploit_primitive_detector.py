#!/usr/bin/env python3
"""
Exploitation Primitive Detector for KernelHunt Framework
Identifies common exploitation primitives in Windows kernel drivers

By Shravan Kumar Sheri (SSK)
"""

import os
import sys
import re
import json
import argparse
from pathlib import Path
from collections import defaultdict

class ExploitPrimitiveDetector:
    """Detect exploitation primitives in decompiled driver code"""

    # Patterns for arbitrary read primitives
    ARBITRARY_READ_PATTERNS = [
        {
            'name': 'MmMapIoSpace + User Address',
            'severity': 'CRITICAL',
            'pattern': r'MmMapIoSpace.*\(',
            'context_check': ['InputBuffer', 'param_', 'user', 'input'],
            'description': 'Physical memory mapping with potentially user-controlled address'
        },
        {
            'name': 'READ_PORT with User Address',
            'severity': 'CRITICAL',
            'pattern': r'READ_PORT_(UCHAR|USHORT|ULONG)\s*\(',
            'context_check': ['InputBuffer', 'param_', 'user'],
            'description': 'Port I/O read with potentially user-controlled address'
        },
        {
            'name': 'ProbeForRead without validation',
            'severity': 'HIGH',
            'pattern': r'ProbeForRead\s*\(',
            'context_check': ['InputBuffer'],
            'description': 'Memory probe that may leak kernel data'
        },
        {
            'name': '__readmsr User-Controlled',
            'severity': 'CRITICAL',
            'pattern': r'__readmsr\s*\(',
            'context_check': ['InputBuffer', 'param_', 'user'],
            'description': 'MSR read with user-controlled MSR number'
        }
    ]

    # Patterns for arbitrary write primitives
    ARBITRARY_WRITE_PATTERNS = [
        {
            'name': 'MmMapIoSpace + memcpy Write',
            'severity': 'CRITICAL',
            'pattern': r'(MmMapIoSpace.*memcpy|memcpy.*MmMapIoSpace)',
            'context_check': ['InputBuffer'],
            'description': 'Physical memory write primitive via mapping + copy'
        },
        {
            'name': 'WRITE_PORT with User Data',
            'severity': 'CRITICAL',
            'pattern': r'WRITE_PORT_(UCHAR|USHORT|ULONG)\s*\(',
            'context_check': ['InputBuffer', 'param_'],
            'description': 'Port I/O write with user-controlled address/data'
        },
        {
            'name': '__writemsr User-Controlled',
            'severity': 'CRITICAL',
            'pattern': r'__writemsr\s*\(',
            'context_check': ['InputBuffer', 'param_', 'user'],
            'description': 'MSR write - can disable SMEP/SMAP/other protections'
        },
        {
            'name': 'memcpy to Kernel Buffer',
            'severity': 'HIGH',
            'pattern': r'memcpy\s*\([^,]+,\s*InputBuffer',
            'context_check': [],
            'description': 'Copy from user buffer without proper size validation'
        },
        {
            'name': 'ZwMapViewOfSection User Address',
            'severity': 'CRITICAL',
            'pattern': r'ZwMapViewOfSection\s*\(',
            'context_check': ['InputBuffer', 'user'],
            'description': 'Map view of section with user-controlled parameters'
        }
    ]

    # Patterns for code execution primitives
    CODE_EXECUTION_PATTERNS = [
        {
            'name': 'Function Pointer from User Input',
            'severity': 'CRITICAL',
            'pattern': r'\(\*[a-zA-Z_][a-zA-Z0-9_]*\)\s*\(',
            'context_check': ['InputBuffer', 'param_'],
            'description': 'Indirect call through potentially user-controlled function pointer'
        },
        {
            'name': 'Callback Registration',
            'severity': 'HIGH',
            'pattern': r'(ExRegisterCallback|IoRegisterShutdownNotification|KeInitializeApc)\s*\(',
            'context_check': ['InputBuffer', 'param_'],
            'description': 'Register callback with potentially user-controlled address'
        },
        {
            'name': 'Thread Creation with User Code',
            'severity': 'CRITICAL',
            'pattern': r'PsCreateSystemThread\s*\(',
            'context_check': ['InputBuffer', 'user'],
            'description': 'Create kernel thread with user-controlled start address'
        }
    ]

    # Patterns for privilege escalation
    PRIVILEGE_ESCALATION_PATTERNS = [
        {
            'name': 'Token Manipulation',
            'severity': 'CRITICAL',
            'pattern': r'(PsReferencePrimaryToken|SeAccessCheck|SeSinglePrivilegeCheck)\s*\(',
            'context_check': ['InputBuffer'],
            'description': 'Token manipulation that may allow privilege escalation'
        },
        {
            'name': 'Process/Thread Manipulation',
            'severity': 'HIGH',
            'pattern': r'(PsLookupProcessByProcessId|PsLookupThreadByThreadId)\s*\(',
            'context_check': ['InputBuffer', 'param_'],
            'description': 'Process/thread access with user-controlled PID/TID'
        },
        {
            'name': 'No Privilege Check Before Dangerous Op',
            'severity': 'HIGH',
            'pattern': r'(MmMapIoSpace|__writemsr|WRITE_PORT_)',
            'missing_check': ['ExGetPreviousMode', 'SePrivilegeCheck', 'IsUserAdmin'],
            'description': 'Dangerous operation without privilege validation'
        }
    ]

    # Patterns for information disclosure
    INFO_LEAK_PATTERNS = [
        {
            'name': 'Kernel Address Leak',
            'severity': 'MEDIUM',
            'pattern': r'(RtlCopyMemory|memcpy)\s*\([^,]*OutputBuffer',
            'context_check': ['kernel', 'Driver', 'System'],
            'description': 'Potential kernel address leak to user mode'
        },
        {
            'name': 'Uninitialized Memory Disclosure',
            'severity': 'MEDIUM',
            'pattern': r'ExAllocatePool.*\(',
            'missing_pattern': r'RtlZeroMemory|memset',
            'description': 'Allocated memory not zeroed before use - may leak data'
        }
    ]

    # Patterns for missing input validation (HIGH-VALUE for 0-day discovery)
    MISSING_VALIDATION_PATTERNS = [
        {
            'name': 'Missing Size Validation',
            'severity': 'HIGH',
            'dangerous_func': r'(memcpy|RtlCopyMemory|memmove)\s*\(',
            'validation_patterns': [
                r'if\s*\(.*InputBufferLength\s*[<>]=',
                r'if\s*\(.*size\s*[<>]',
                r'if\s*\(.*length\s*[<>]',
            ],
            'description': 'Buffer operation without proper size validation - HIGH 0-DAY POTENTIAL'
        },
        {
            'name': 'Missing Privilege Check',
            'severity': 'CRITICAL',
            'dangerous_func': r'(MmMapIoSpace|__writemsr|WRITE_PORT_|ZwMapViewOfSection)\s*\(',
            'validation_patterns': [
                r'ExGetPreviousMode',
                r'SePrivilegeCheck',
                r'IsUserAnAdmin',
                r'if.*RequestorMode.*==.*KernelMode',
            ],
            'description': 'Dangerous operation without privilege validation - CRITICAL 0-DAY'
        },
        {
            'name': 'Missing NULL Check',
            'severity': 'MEDIUM',
            'dangerous_func': r'(->|ExAllocatePool)',
            'validation_patterns': [
                r'if\s*\(.*==\s*NULL\)',
                r'if\s*\(.*!=\s*NULL\)',
                r'if\s*\(.*\)',
            ],
            'description': 'Potential NULL pointer dereference'
        },
        {
            'name': 'Missing Range Check',
            'severity': 'HIGH',
            'dangerous_func': r'\[\s*[a-zA-Z_][a-zA-Z0-9_]*\s*\]',  # Array access
            'validation_patterns': [
                r'if\s*\(.*[<>]=.*MAX',
                r'if\s*\(.*[<>]',
            ],
            'description': 'Array access without bounds checking - potential buffer overflow'
        }
    ]

    def __init__(self, analysis_dir):
        self.analysis_dir = Path(analysis_dir)
        self.c_files = []
        self.primitives_found = defaultdict(list)
        self.control_flow_findings = []  # Track control flow from input to sink

        if not self.analysis_dir.exists():
            raise FileNotFoundError(f"Analysis directory not found: {analysis_dir}")

    def analyze(self):
        """Analyze all C files for exploitation primitives"""
        print(f"\n[*] Analyzing for exploitation primitives in: {self.analysis_dir}")

        self.c_files = list(self.analysis_dir.glob("*.c"))
        print(f"[*] Found {len(self.c_files)} C files to analyze\n")

        for c_file in self.c_files:
            self.analyze_file(c_file)

        # Run control flow analysis
        print("[*] Running control flow analysis...")
        self.analyze_control_flow()

        self.save_results()
        self.display_results()

    def analyze_file(self, filepath):
        """Analyze a single C file"""
        try:
            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()

            # Check for each primitive type
            self.check_arbitrary_read(filepath, content)
            self.check_arbitrary_write(filepath, content)
            self.check_code_execution(filepath, content)
            self.check_privilege_escalation(filepath, content)
            self.check_info_leak(filepath, content)

            # NEW: Check for missing input validation (HIGH-VALUE)
            self.check_missing_validation(filepath, content)

        except Exception as e:
            pass

    def check_arbitrary_read(self, filepath, content):
        """Check for arbitrary read primitives"""
        for pattern_info in self.ARBITRARY_READ_PATTERNS:
            matches = re.finditer(pattern_info['pattern'], content, re.IGNORECASE)

            for match in matches:
                # Get context around match
                start = max(0, match.start() - 200)
                end = min(len(content), match.end() + 200)
                context = content[start:end]

                # Check if user input is involved
                has_user_input = any(check in context for check in pattern_info['context_check'])

                if has_user_input or not pattern_info['context_check']:
                    self.primitives_found['arbitrary_read'].append({
                        'name': pattern_info['name'],
                        'severity': pattern_info['severity'],
                        'description': pattern_info['description'],
                        'file': filepath.name,
                        'match': match.group(0),
                        'context': self.clean_context(context)
                    })

    def check_arbitrary_write(self, filepath, content):
        """Check for arbitrary write primitives"""
        for pattern_info in self.ARBITRARY_WRITE_PATTERNS:
            matches = re.finditer(pattern_info['pattern'], content, re.IGNORECASE | re.DOTALL)

            for match in matches:
                start = max(0, match.start() - 200)
                end = min(len(content), match.end() + 200)
                context = content[start:end]

                has_user_input = any(check in context for check in pattern_info['context_check'])

                if has_user_input or not pattern_info['context_check']:
                    self.primitives_found['arbitrary_write'].append({
                        'name': pattern_info['name'],
                        'severity': pattern_info['severity'],
                        'description': pattern_info['description'],
                        'file': filepath.name,
                        'match': match.group(0),
                        'context': self.clean_context(context)
                    })

    def check_code_execution(self, filepath, content):
        """Check for code execution primitives"""
        for pattern_info in self.CODE_EXECUTION_PATTERNS:
            matches = re.finditer(pattern_info['pattern'], content, re.IGNORECASE)

            for match in matches:
                start = max(0, match.start() - 200)
                end = min(len(content), match.end() + 200)
                context = content[start:end]

                has_user_input = any(check in context for check in pattern_info['context_check'])

                if has_user_input or not pattern_info['context_check']:
                    self.primitives_found['code_execution'].append({
                        'name': pattern_info['name'],
                        'severity': pattern_info['severity'],
                        'description': pattern_info['description'],
                        'file': filepath.name,
                        'match': match.group(0),
                        'context': self.clean_context(context)
                    })

    def check_privilege_escalation(self, filepath, content):
        """Check for privilege escalation primitives"""
        for pattern_info in self.PRIVILEGE_ESCALATION_PATTERNS:
            if 'missing_check' in pattern_info:
                # Check if dangerous operation exists without privilege check
                matches = re.finditer(pattern_info['pattern'], content, re.IGNORECASE)

                for match in matches:
                    # Check if privilege validation is missing
                    start = max(0, match.start() - 500)
                    end = min(len(content), match.end() + 100)
                    func_context = content[start:end]

                    has_priv_check = any(check in func_context for check in pattern_info['missing_check'])

                    if not has_priv_check:
                        self.primitives_found['privilege_escalation'].append({
                            'name': pattern_info['name'],
                            'severity': pattern_info['severity'],
                            'description': pattern_info['description'],
                            'file': filepath.name,
                            'match': match.group(0),
                            'context': self.clean_context(func_context[:300])
                        })
            else:
                matches = re.finditer(pattern_info['pattern'], content, re.IGNORECASE)

                for match in matches:
                    start = max(0, match.start() - 200)
                    end = min(len(content), match.end() + 200)
                    context = content[start:end]

                    has_user_input = any(check in context for check in pattern_info['context_check'])

                    if has_user_input or not pattern_info['context_check']:
                        self.primitives_found['privilege_escalation'].append({
                            'name': pattern_info['name'],
                            'severity': pattern_info['severity'],
                            'description': pattern_info['description'],
                            'file': filepath.name,
                            'match': match.group(0),
                            'context': self.clean_context(context)
                        })

    def check_info_leak(self, filepath, content):
        """Check for information disclosure"""
        for pattern_info in self.INFO_LEAK_PATTERNS:
            if 'missing_pattern' in pattern_info:
                # Check for pattern that should exist but doesn't
                matches = re.finditer(pattern_info['pattern'], content, re.IGNORECASE)

                for match in matches:
                    start = max(0, match.start() - 100)
                    end = min(len(content), match.end() + 200)
                    context = content[start:end]

                    has_missing = not re.search(pattern_info['missing_pattern'], context, re.IGNORECASE)

                    if has_missing:
                        self.primitives_found['info_leak'].append({
                            'name': pattern_info['name'],
                            'severity': pattern_info['severity'],
                            'description': pattern_info['description'],
                            'file': filepath.name,
                            'match': match.group(0),
                            'context': self.clean_context(context)
                        })
            else:
                matches = re.finditer(pattern_info['pattern'], content, re.IGNORECASE)

                for match in matches:
                    start = max(0, match.start() - 200)
                    end = min(len(content), match.end() + 200)
                    context = content[start:end]

                    has_context = any(check in context for check in pattern_info.get('context_check', []))

                    if has_context or not pattern_info.get('context_check'):
                        self.primitives_found['info_leak'].append({
                            'name': pattern_info['name'],
                            'severity': pattern_info['severity'],
                            'description': pattern_info['description'],
                            'file': filepath.name,
                            'match': match.group(0),
                            'context': self.clean_context(context)
                        })

    def check_missing_validation(self, filepath, content):
        """
        Check for missing input validation - HIGHEST VALUE for 0-day discovery!
        This finds vulnerabilities where dangerous operations lack proper validation.
        """
        for pattern_info in self.MISSING_VALIDATION_PATTERNS:
            dangerous_matches = re.finditer(pattern_info['dangerous_func'], content, re.IGNORECASE)

            for match in dangerous_matches:
                # Get larger context to look for validation
                start = max(0, match.start() - 500)
                end = min(len(content), match.end() + 100)
                func_context = content[start:end]

                # Check if ANY validation pattern exists
                has_validation = False
                for val_pattern in pattern_info['validation_patterns']:
                    if re.search(val_pattern, func_context, re.IGNORECASE):
                        has_validation = True
                        break

                # If validation is MISSING, this is a potential vulnerability!
                if not has_validation:
                    # Calculate confidence based on context
                    confidence = self.calculate_vuln_confidence(match.group(0), func_context)

                    if confidence >= 50:  # Only report medium+ confidence
                        self.primitives_found['missing_validation'].append({
                            'name': pattern_info['name'],
                            'severity': pattern_info['severity'],
                            'description': pattern_info['description'],
                            'file': filepath.name,
                            'match': match.group(0),
                            'context': self.clean_context(func_context[:300]),
                            'confidence': confidence,
                            'exploitation_tip': self.get_exploitation_tip(pattern_info['name'])
                        })

    def calculate_vuln_confidence(self, dangerous_func, context):
        """Calculate confidence (0-100) that this is a real vulnerability."""
        confidence = 60  # Start with medium confidence

        # Boost confidence
        if 'InputBuffer' in context:
            confidence += 20  # Direct user input
        if 'IRP' in context and 'DeviceIoControl' in context:
            confidence += 15  # IOCTL handler
        if 'param_' in context:
            confidence += 10  # Function parameter (likely user-controlled)

        # Reduce confidence
        if 'if (' in context:
            confidence -= 10  # Some validation exists nearby
        if 'STATUS_INVALID' in context:
            confidence -= 5  # Error handling present

        # Specific dangerous operations boost confidence
        if '__writemsr' in dangerous_func or 'MmMapIoSpace' in dangerous_func:
            confidence += 15  # Highly dangerous operations

        return max(0, min(100, confidence))

    def get_exploitation_tip(self, vuln_name):
        """Provide exploitation guidance for discovered vulnerabilities."""
        tips = {
            'Missing Size Validation': 'Craft IOCTL with oversized buffer to trigger buffer overflow',
            'Missing Privilege Check': 'Call from low-privilege process to escalate privileges',
            'Missing NULL Check': 'Trigger allocation failure to cause NULL deref, may lead to arbitrary write',
            'Missing Range Check': 'Provide out-of-bounds index to read/write arbitrary memory'
        }
        return tips.get(vuln_name, 'Analyze control flow to determine exploitability')

    def analyze_control_flow(self):
        """
        Basic control flow analysis: Track data flow from user input to dangerous sinks.
        This improves accuracy by confirming user input reaches dangerous operations.
        """
        # Look for IOCTL dispatch functions
        dispatch_files = []
        for c_file in self.c_files:
            name_lower = c_file.stem.lower()
            if any(keyword in name_lower for keyword in ['dispatch', 'ioctl', 'devicecontrol']):
                dispatch_files.append(c_file)

        if not dispatch_files:
            return

        print(f"[*] Found {len(dispatch_files)} potential dispatch functions")

        for dispatch_file in dispatch_files[:10]:  # Analyze top 10
            try:
                content = dispatch_file.read_text(encoding='utf-8', errors='ignore')

                # Find control flow: InputBuffer -> dangerous operation
                self.trace_input_to_sink(dispatch_file, content)

            except Exception as e:
                pass

    def trace_input_to_sink(self, filepath, content):
        """Trace data flow from user input to dangerous operations."""
        # Find variable assignments from InputBuffer
        input_vars = []
        input_pattern = r'([a-zA-Z_][a-zA-Z0-9_]*)\s*=\s*.*InputBuffer'
        for match in re.finditer(input_pattern, content):
            var_name = match.group(1)
            input_vars.append(var_name)

        if not input_vars:
            return

        # Check if these variables reach dangerous sinks
        dangerous_sinks = [
            r'MmMapIoSpace\s*\([^)]*{var}',
            r'memcpy\s*\([^,]*,\s*{var}',
            r'__writemsr\s*\([^)]*{var}',
            r'WRITE_PORT_\w+\s*\([^)]*{var}',
        ]

        for var in input_vars:
            for sink_pattern in dangerous_sinks:
                pattern = sink_pattern.format(var=var)
                if re.search(pattern, content, re.IGNORECASE):
                    self.control_flow_findings.append({
                        'file': filepath.name,
                        'input_var': var,
                        'sink': sink_pattern.split('\\s')[0],
                        'description': f'User input variable "{var}" flows to dangerous sink',
                        'severity': 'CRITICAL'
                    })

    def clean_context(self, context):
        """Clean up context for display"""
        # Remove excessive whitespace
        context = re.sub(r'\s+', ' ', context)
        # Truncate if too long
        if len(context) > 200:
            context = context[:200] + '...'
        return context.strip()

    def save_results(self):
        """Save results to JSON with enhanced analysis data"""
        output_file = self.analysis_dir / "exploitation_primitives.json"

        results = {
            'summary': {
                'total_primitives': sum(len(v) for v in self.primitives_found.values()),
                'by_type': {k: len(v) for k, v in self.primitives_found.items()},
                'critical_count': sum(1 for primitives in self.primitives_found.values()
                                     for p in primitives if p['severity'] == 'CRITICAL'),
                'control_flow_findings': len(self.control_flow_findings),
                'high_confidence_vulns': sum(1 for primitives in self.primitives_found.values()
                                            for p in primitives if p.get('confidence', 0) >= 70)
            },
            'primitives': dict(self.primitives_found),
            'control_flow_analysis': self.control_flow_findings
        }

        with open(output_file, 'w') as f:
            json.dump(results, f, indent=2)

        print(f"\n[+] Results saved to: {output_file}")
        print(f"[+] High-confidence vulnerabilities: {results['summary']['high_confidence_vulns']}")

    def display_results(self):
        """Display found exploitation primitives"""
        print(f"\n{'='*80}")
        print("EXPLOITATION PRIMITIVES DETECTED")
        print(f"{'='*80}\n")

        if not self.primitives_found:
            print("[!] No exploitation primitives found")
            return

        total = sum(len(v) for v in self.primitives_found.values())
        critical = sum(1 for primitives in self.primitives_found.values()
                      for p in primitives if p['severity'] == 'CRITICAL')

        print(f"Total Primitives Found: {total}")
        print(f"Critical Severity: {critical}\n")

        # Display by category
        categories = [
            ('missing_validation', 'üö® MISSING INPUT VALIDATION (HIGH 0-DAY POTENTIAL)', '‚ïê'),
            ('arbitrary_read', 'üîç ARBITRARY READ PRIMITIVES', '‚ïê'),
            ('arbitrary_write', '‚úçÔ∏è  ARBITRARY WRITE PRIMITIVES', '‚ïê'),
            ('code_execution', '‚ö° CODE EXECUTION PRIMITIVES', '‚ïê'),
            ('privilege_escalation', 'üîì PRIVILEGE ESCALATION', '‚ïê'),
            ('info_leak', 'üì§ INFORMATION DISCLOSURE', '‚ïê')
        ]

        for key, title, sep in categories:
            primitives = self.primitives_found.get(key, [])
            if not primitives:
                continue

            print(f"\n{title}")
            print(sep * 80)

            # Group by name
            grouped = defaultdict(list)
            for prim in primitives:
                grouped[prim['name']].append(prim)

            for name, items in grouped.items():
                severity = items[0]['severity']
                color = ''
                if severity == 'CRITICAL':
                    color = 'üî¥'
                elif severity == 'HIGH':
                    color = 'üü†'
                elif severity == 'MEDIUM':
                    color = 'üü°'

                print(f"\n{color} {name} ({severity})")
                print(f"   {items[0]['description']}")

                # Show confidence if available
                if 'confidence' in items[0]:
                    avg_conf = sum(p.get('confidence', 0) for p in items) / len(items)
                    print(f"   Confidence: {avg_conf:.0f}%")

                # Show exploitation tip if available
                if 'exploitation_tip' in items[0]:
                    print(f"   üí° Exploitation: {items[0]['exploitation_tip']}")

                print(f"   Found in: {', '.join(set([p['file'] for p in items]))}")
                print(f"   Occurrences: {len(items)}")

        # Display control flow findings
        if self.control_flow_findings:
            print(f"\nüéØ CONTROL FLOW ANALYSIS (Input ‚Üí Dangerous Sink)")
            print('‚ïê' * 80)
            for finding in self.control_flow_findings:
                print(f"\nüî¥ {finding['description']}")
                print(f"   Variable: {finding['input_var']} ‚Üí Sink: {finding['sink']}")
                print(f"   File: {finding['file']}")

        print(f"\n{'='*80}\n")


def main():
    parser = argparse.ArgumentParser(
        description='Detect exploitation primitives in decompiled driver code',
        epilog='Example: python exploit_primitive_detector.py -d analysis_results/driver_name'
    )

    parser.add_argument('-d', '--dir', required=True,
                        help='Directory containing decompiled C files')

    args = parser.parse_args()

    try:
        detector = ExploitPrimitiveDetector(args.dir)
        detector.analyze()

    except Exception as e:
        print(f"\n[!] Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
